diff --git a/pom.xml b/pom.xml
index 404c73f..7470244 100644
--- a/pom.xml
+++ b/pom.xml
@@ -123,6 +123,11 @@
             <artifactId>tls-sig-api-v2</artifactId>
             <version>2.0</version>
         </dependency>
+        <dependency>
+            <groupId>com.huaban</groupId>
+            <artifactId>jieba-analysis</artifactId>
+            <version>1.0.2</version>
+        </dependency>
     </dependencies>
 
     <build>
diff --git a/src/main/java/com/szu/afternoon3/platform/entity/mongo/PostDoc.java b/src/main/java/com/szu/afternoon3/platform/entity/mongo/PostDoc.java
index 86d5d8e..cb7fe1b 100644
--- a/src/main/java/com/szu/afternoon3/platform/entity/mongo/PostDoc.java
+++ b/src/main/java/com/szu/afternoon3/platform/entity/mongo/PostDoc.java
@@ -5,6 +5,7 @@ import org.springframework.data.annotation.Id;
 import org.springframework.data.mongodb.core.index.Indexed;
 import org.springframework.data.mongodb.core.index.TextIndexed;
 import org.springframework.data.mongodb.core.mapping.Document;
+import org.springframework.data.mongodb.core.mapping.TextScore;
 
 import java.time.LocalDateTime;
 import java.util.List;
@@ -22,16 +23,20 @@ public class PostDoc {
     private String userNickname;
     private String userAvatar;
 
-//    @TextIndexed(weight = 2) // 权重2：标题匹配
-//    @Indexed
+    // 标题和内容不需要 @TextIndexed 了，因为我们统一搜索 searchTerms
     private String title;
-
-//    @TextIndexed(weight = 1) // 权重1：内容匹配
     private String content;
 
-//    @TextIndexed(weight = 3) // 新增全文索引，用于模糊搜索 (searchPosts)
     @Indexed           // 保留普通索引，用于精确筛选 (getPostList)
     private List<String> tags;
+    // 【新增】搜索专用字段
+    // weight=5 表示匹配到这里的词，相关度得分很高
+    @TextIndexed(weight = 5)
+    private List<String> searchTerms;
+
+    // 【新增】用于接收查询时的匹配分数 (不会存入数据库)
+    @TextScore
+    private Float score;
 
     // 统计数据
     private Integer viewCount = 0;
diff --git a/src/main/java/com/szu/afternoon3/platform/service/impl/PostServiceImpl.java b/src/main/java/com/szu/afternoon3/platform/service/impl/PostServiceImpl.java
index 2aeee73..ef2ced8 100644
--- a/src/main/java/com/szu/afternoon3/platform/service/impl/PostServiceImpl.java
+++ b/src/main/java/com/szu/afternoon3/platform/service/impl/PostServiceImpl.java
@@ -17,6 +17,7 @@ import com.szu.afternoon3.platform.exception.AppException;
 import com.szu.afternoon3.platform.exception.ResultCode;
 import com.szu.afternoon3.platform.repository.*;
 import com.szu.afternoon3.platform.service.PostService;
+import com.szu.afternoon3.platform.util.SearchHelper;
 import com.szu.afternoon3.platform.vo.PostVO;
 import com.szu.afternoon3.platform.vo.UserInfo;
 import com.szu.afternoon3.platform.dto.PostCreateDTO;
@@ -30,6 +31,8 @@ import org.springframework.data.mongodb.core.aggregation.Aggregation;
 import org.springframework.data.mongodb.core.aggregation.AggregationResults;
 import org.springframework.data.mongodb.core.query.Criteria;
 import org.springframework.data.mongodb.core.query.Query;
+import org.springframework.data.mongodb.core.query.TextCriteria;
+import org.springframework.data.mongodb.core.query.TextQuery;
 import org.springframework.data.redis.core.StringRedisTemplate;
 import org.springframework.stereotype.Service;
 
@@ -55,7 +58,8 @@ public class PostServiceImpl implements PostService {
     private MongoTemplate mongoTemplate;
     @Autowired
     private UserMapper userMapper;
-
+    @Autowired
+    private SearchHelper searchHelper; // 【注入 Helper】
     @Autowired
     private ApplicationEventPublisher eventPublisher;
     @Override
@@ -98,53 +102,70 @@ public class PostServiceImpl implements PostService {
         return buildResultMap(postDocPage);
     }
 
-    // 因为text index对于中文支持不友好，还是换回了正则
     @Override
     public Map<String, Object> searchPosts(String keyword, Integer page, Integer size) {
         int pageNum = (page == null || page < 1) ? 0 : page - 1;
         int pageSize = (size == null || size < 1) ? 20 : size;
 
-        // 1. 如果关键词为空，返回空列表
         if (StrUtil.isBlank(keyword)) {
-            Pageable pageable = PageRequest.of(pageNum, pageSize, Sort.by(Sort.Direction.DESC, "createdAt"));
-            return buildResultMap(Page.empty(pageable));
+            return buildResultMap(Page.empty(PageRequest.of(pageNum, pageSize)));
         }
 
-        // 2. 关键词转义，防止正则报错
-        String safeKeyword = java.util.regex.Pattern.quote(keyword);
-        String regex = ".*" + safeKeyword + ".*";
+        // 1. 使用 Jieba 处理用户的搜索词
+        // 用户搜 "深大美食" -> 转换成 "深大 美食" (Mongo会理解为 OR 关系)
+        String searchString = searchHelper.analyzeKeyword(keyword);
 
-        // 3. 构建查询 Query
-        Query query = new Query();
+        // 兜底：如果分词后为空 (比如用户只输入了标点)，就用原词
+        if (StrUtil.isBlank(searchString)) {
+            searchString = keyword;
+        }
 
-        // 基础条件：未删除、已发布
+        // 2. 构建全文检索条件
+        // matching() 会自动去匹配 PostDoc 中带有 @TextIndexed 的字段 (即 searchTerms)
+        TextCriteria criteria = TextCriteria.forDefaultLanguage().matching(searchString);
+
+        // 3. 构建查询对象
+        // sortByScore: 按匹配度排序 (相关性高的在前，比如同时包含 "深大" 和 "美食" 的)
+        Query query = TextQuery.queryText(criteria).sortByScore();
+
+        // 4. 叠加状态过滤
         query.addCriteria(Criteria.where("isDeleted").is(0));
         query.addCriteria(Criteria.where("status").is(1));
 
-        // 核心匹配逻辑：(标题 包含 OR 内容 包含 OR 标签 包含)
-        // 注意：这里无法像 Text Index 那样自动计算 score 权重，
-        // 但对于大作业来说，能搜出来比搜得准更重要。
-        query.addCriteria(new Criteria().orOperator(
-                Criteria.where("title").regex(regex, "i"),
-                Criteria.where("content").regex(regex, "i"),
-                Criteria.where("tags").regex(regex, "i")
-        ));
-
-        // 4. 排序：按时间倒序（搜索结果通常也希望看新的）
-        // 如果想实现“匹配度排序”，在不使用搜索引擎(ES)的情况下比较复杂，
-        // 简单的做法是先按时间排，解决 90% 的需求。
-        Pageable pageable = PageRequest.of(pageNum, pageSize, Sort.by(Sort.Direction.DESC, "createdAt"));
+        // 5. 分页
+        Pageable pageable = PageRequest.of(pageNum, pageSize);
         query.with(pageable);
 
-        // 5. 执行查询
+        // 6. 执行
         long total = mongoTemplate.count(query, PostDoc.class);
         List<PostDoc> list = mongoTemplate.find(query, PostDoc.class);
 
-        // 6. 封装结果
-        Page<PostDoc> postDocPage = new PageImpl<>(list, pageable, total);
-        return buildResultMap(postDocPage);
-    }
+        // 降级逻辑,使用正则
+        if (total == 0) {
+            // log.info("Text Index 未命中，降级为 Regex 搜索: {}", keyword);
+            query = new Query();
+            String safeKeyword = java.util.regex.Pattern.quote(keyword);
+            String regex = ".*" + safeKeyword + ".*";
+
+            // 注意：这里要搜 title, content, tags，不要搜 searchTerms (因为 searchTerms 是切碎的)
+            query.addCriteria(new Criteria().orOperator(
+                    Criteria.where("title").regex(regex, "i"),
+                    Criteria.where("content").regex(regex, "i"),
+                    Criteria.where("tags").regex(regex, "i")
+            ));
+
+            query.addCriteria(Criteria.where("isDeleted").is(0));
+            query.addCriteria(Criteria.where("status").is(1));
+            query.with(pageable);
+
+            total = mongoTemplate.count(query, PostDoc.class);
+            list = mongoTemplate.find(query, PostDoc.class);
+        } else {
+            list = mongoTemplate.find(query, PostDoc.class);
+        }
 
+        return buildResultMap(new PageImpl<>(list, pageable, total));
+    }
     @Override
     public PostVO getPostDetail(String postId) {
         PostDoc doc = postRepository.findById(postId).orElse(null);
@@ -174,63 +195,53 @@ public class PostServiceImpl implements PostService {
             return new ArrayList<>();
         }
 
-        // --- 核心中文匹配逻辑 ---
+        // 【架构说明】
+        // 联想词 (Autocomplete) 需要 "前缀匹配" 或 "包含匹配" (如输入 "深" -> 提示 "深圳")。
+        // MongoDB 的 Text Index 是 "分词匹配" (输入 "深" 无法匹配 "深圳")。
+        // 因此，对于联想词功能，RegEx (正则) 依然是最佳选择。
+        // 我们只在 title 和 tags 上做正则，性能是可控的。
 
-        // 1. 转义关键词中的特殊字符
         String safeKeyword = java.util.regex.Pattern.quote(keyword);
-
-        // 2. 定义正则规则 (包含匹配)
         String regex = ".*" + safeKeyword + ".*";
 
-        // 3. 构建查询
         Query query = new Query();
         query.addCriteria(Criteria.where("isDeleted").is(0));
         query.addCriteria(Criteria.where("status").is(1));
 
-        // 4. OR 查询
+        // 只查 tags 和 title，不查 searchTerms (因为 searchTerms 太碎了)
         query.addCriteria(new Criteria().orOperator(
                 Criteria.where("tags").regex(regex, "i"),
                 Criteria.where("title").regex(regex, "i")
         ));
 
-        // 5. 优化查询字段
         query.limit(20);
         query.fields().include("title").include("tags");
 
-        // 6. 执行查询
         List<PostDoc> docs = mongoTemplate.find(query, PostDoc.class);
-
-        // 7. 数据清洗与排序
         Set<String> suggestions = new LinkedHashSet<>();
 
-        // 策略：优先展示匹配到的【标签】
         for (PostDoc doc : docs) {
+            // 优先推荐 Tag
             if (CollUtil.isNotEmpty(doc.getTags())) {
                 for (String tag : doc.getTags()) {
-                    // 【修改点 1】: 包含关键词 且 不完全等于关键词
                     if (StrUtil.contains(tag, keyword) && !StrUtil.equals(tag, keyword)) {
                         suggestions.add(tag);
                     }
                 }
             }
         }
-
-        // 策略：其次展示匹配到的【标题】
         for (PostDoc doc : docs) {
+            // 其次推荐标题
             String title = doc.getTitle();
-            // 【修改点 2】: 包含关键词 且 不完全等于关键词
             if (StrUtil.contains(title, keyword) && !StrUtil.equals(title, keyword)) {
-                // 这里暂不做截断
                 suggestions.add(title);
             }
-
-            if (suggestions.size() >= 15) {
-                break;
-            }
+            if (suggestions.size() >= 10) break;
         }
 
         return new ArrayList<>(suggestions);
     }
+
     @Autowired
     private StringRedisTemplate redisTemplate;
     /**
@@ -395,7 +406,11 @@ public class PostServiceImpl implements PostService {
         // 4. 严格互斥逻辑
         post.setType(dto.getType());
 
-        // --- 核心：资源与封面处理 ---
+        // 【核心修改】生成分词并存入
+        List<String> terms = searchHelper.generateSearchTerms(dto.getTitle(), dto.getContent(), dto.getTags());
+        post.setSearchTerms(terms);
+
+        // --- 资源与封面处理 ---
         List<String> finalResources = new ArrayList<>();
         String finalCover = "";
 
@@ -555,6 +570,9 @@ public class PostServiceImpl implements PostService {
 
         // 3. 状态重置与保存
         if (needAudit) {
+            // 如果文本变了，重新生成分词
+            List<String> terms = searchHelper.generateSearchTerms(post.getTitle(), post.getContent(), post.getTags());
+            post.setSearchTerms(terms);
             post.setStatus(0); // 重置为审核中
         }
         post.setUpdatedAt(java.time.LocalDateTime.now());
diff --git a/src/main/java/com/szu/afternoon3/platform/util/SearchHelper.java b/src/main/java/com/szu/afternoon3/platform/util/SearchHelper.java
new file mode 100644
index 0000000..f9cec4f
--- /dev/null
+++ b/src/main/java/com/szu/afternoon3/platform/util/SearchHelper.java
@@ -0,0 +1,66 @@
+package com.szu.afternoon3.platform.util;
+
+import cn.hutool.core.collection.CollUtil;
+import cn.hutool.core.util.StrUtil;
+import com.huaban.analysis.jieba.JiebaSegmenter;
+import com.huaban.analysis.jieba.SegToken;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.data.mongodb.core.MongoTemplate;
+import org.springframework.stereotype.Component;
+
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+@Component
+public class SearchHelper {
+    private final JiebaSegmenter segmenter = new JiebaSegmenter();
+
+    public List<String> generateSearchTerms(String title, String content, List<String> tags) {
+        Set<String> terms = new HashSet<>();
+
+        if (StrUtil.isNotBlank(title)) {
+            // 【关键修改】改用 INDEX 模式，切得更碎
+            // 例如 "深圳大学" -> "深圳", "大学", "深圳大学"
+            processText(title, terms, JiebaSegmenter.SegMode.INDEX);
+        }
+
+        if (StrUtil.isNotBlank(content)) {
+            // 内容依然用 SEARCH 模式，避免索引爆炸
+            processText(content, terms, JiebaSegmenter.SegMode.SEARCH);
+        }
+
+        if (CollUtil.isNotEmpty(tags)) {
+            for (String tag : tags) {
+                terms.add(tag); // 保留原标签
+                // 标签通常较短，用 INDEX 模式切分更保险
+                processText(tag, terms, JiebaSegmenter.SegMode.INDEX);
+            }
+        }
+
+        return new ArrayList<>(terms);
+    }
+
+    public String analyzeKeyword(String keyword) {
+        if (StrUtil.isBlank(keyword)) return "";
+        List<SegToken> tokens = segmenter.process(keyword, JiebaSegmenter.SegMode.SEARCH);
+        return tokens.stream()
+                .map(t -> t.word.toLowerCase()) // 转小写
+                .collect(Collectors.joining(" "));
+    }
+
+    private void processText(String text, Set<String> result, JiebaSegmenter.SegMode mode) {
+        if (StrUtil.isBlank(text)) return;
+
+        List<SegToken> tokens = segmenter.process(text, mode);
+        for (SegToken token : tokens) {
+            String word = token.word;
+            // 过滤逻辑保持不变：长度>1 或 纯字母/数字
+            if (word.length() > 1 || word.matches("[a-zA-Z]+") || StrUtil.isNumeric(word)) {
+                result.add(word.toLowerCase());
+            }
+        }
+    }
+}
\ No newline at end of file
diff --git a/src/test/java/com/szu/afternoon3/platform/service/SearchIntegrationTest.java b/src/test/java/com/szu/afternoon3/platform/service/SearchIntegrationTest.java
index 68695bc..91df9eb 100644
--- a/src/test/java/com/szu/afternoon3/platform/service/SearchIntegrationTest.java
+++ b/src/test/java/com/szu/afternoon3/platform/service/SearchIntegrationTest.java
@@ -1,186 +1,164 @@
 package com.szu.afternoon3.platform.service;
 
+import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
+import com.szu.afternoon3.platform.dto.PostCreateDTO;
+import com.szu.afternoon3.platform.entity.User;
 import com.szu.afternoon3.platform.entity.mongo.PostDoc;
+import com.szu.afternoon3.platform.mapper.UserMapper;
 import com.szu.afternoon3.platform.repository.PostRepository;
-import org.junit.jupiter.api.Assertions;
-import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.DisplayName;
-import org.junit.jupiter.api.Test;
+import com.szu.afternoon3.platform.util.SearchHelper;
+import com.szu.afternoon3.platform.common.UserContext;
+import org.junit.jupiter.api.*;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.boot.test.context.SpringBootTest;
-import org.springframework.data.domain.Sort;
 import org.springframework.data.mongodb.core.MongoTemplate;
 import org.springframework.data.mongodb.core.index.TextIndexDefinition;
-import org.springframework.test.context.TestPropertySource;
+import org.springframework.transaction.annotation.Transactional;
 
 import java.util.List;
 import java.util.Map;
 
 @SpringBootTest
-@TestPropertySource(properties = "spring.data.mongodb.auto-index-creation=false")
+//@Transactional
 public class SearchIntegrationTest {
 
-    @Autowired
-    private PostService postService;
-
-    @Autowired
-    private PostRepository postRepository;
-
-    @Autowired
-    private MongoTemplate mongoTemplate;
+    @Autowired private SearchHelper searchHelper;
+    @Autowired private PostService postService;
+    @Autowired private PostRepository postRepository;
+    @Autowired private MongoTemplate mongoTemplate;
+    @Autowired private UserMapper userMapper;
 
+    private Long userId;
+    private String userEmail;
     @BeforeEach
     public void setup() {
-        // 1. 删除集合 (清除所有数据和索引)
-        mongoTemplate.dropCollection(PostDoc.class);
+        // 1. 清理环境 (手动清理，因为没了 Transactional)
+        cleanUp();
+
+        // 2. 强制重建索引 (这是最核心的一步)
+        mongoTemplate.dropCollection(PostDoc.class); // 删集合=删索引
 
-        // 2. 手动创建索引 (这一步必须要有，因为我们关掉了自动创建)
         TextIndexDefinition textIndex = new TextIndexDefinition.TextIndexDefinitionBuilder()
-                .onField("tags", 3f)
-                .onField("title", 2f)
-                .onField("content", 1f)
-                .named("TextIndexWithTags")
+                .onField("searchTerms", 5f)
+                .named("PostDoc_TextIndex")
                 .build();
-
         mongoTemplate.indexOps(PostDoc.class).ensureIndex(textIndex);
+
+        // 3. 准备用户
+        User user = new User();
+        user.setNickname("搜索测试员");
+        this.userEmail = "search_test_" + System.currentTimeMillis() + "@szu.edu.cn";
+        user.setEmail(userEmail);
+        user.setStatus(1);
+        userMapper.insert(user);
+        this.userId = user.getId();
+        UserContext.setUserId(userId);
+    }
+    @AfterEach
+    public void tearDown() {
+        // 测试结束后清理垃圾数据
+        cleanUp();
+    }
+    private void cleanUp() {
+        // 清理 Mongo
+        postRepository.deleteAll();
+
+        // 清理 Postgres (手动删，防止 Unique Key 冲突)
+        if (userEmail != null) {
+            userMapper.delete(new LambdaQueryWrapper<User>().eq(User::getEmail, userEmail));
+        }
     }
 
     @Test
-    @DisplayName("测试全文搜索：同时匹配标签、标题、正文")
-    public void testSearchByKeyword() {
-        String keyword = "ArchLinux";
+    @DisplayName("Debug: 查看 Jieba 分词结果")
+    public void debugJiebaTokenization() {
+        String title = "深圳大学的饭堂很好吃";
+        String content = "今天去了南区，发现荔园美食荟有很多新档口。ArchLinux安装也很快。";
+        List<String> tags = List.of("美食探店", "深圳大学");
 
-        // --- 1. 准备测试数据 ---
+        List<String> terms = searchHelper.generateSearchTerms(title, content, tags);
 
-        // A: 标题包含关键字
-        createPost("1", "ArchLinux 安装指南", "这里是正文内容...", List.of("Linux"));
+        System.out.println("Jieba 分词结果: " + terms);
 
-        // B: 正文包含关键字
-        createPost("2", "普通标题", "我觉得 ArchLinux 是最好的发行版", List.of("OS"));
+        // 验证分词 (INDEX模式应该能把 '深圳' 切出来)
+        Assertions.assertTrue(terms.contains("深圳"), "应该包含 '深圳'");
+        Assertions.assertTrue(terms.contains("大学"), "应该包含 '大学'");
 
-        // C: 标签包含关键字 (权重最高)
-        createPost("3", "没有关键字的标题", "没有关键字的正文", List.of("ArchLinux", "Tech"));
+        // 【关键修复 3】: 断言改为小写，匹配分词器的行为
+        Assertions.assertTrue(terms.contains("archlinux"), "应该包含 'archlinux' (小写)");
+    }
 
-        // D: 干扰项 (完全不包含)
-        createPost("4", "Windows 教程", "这里是微软的内容", List.of("Win11"));
+    @Test
+    @DisplayName("验证创建帖子时 searchTerms 是否正确存入 DB")
+    public void testSaveSearchTerms() {
+        PostCreateDTO dto = new PostCreateDTO();
+        dto.setTitle("Java并发编程");
+        dto.setContent("学习多线程和锁机制");
+        dto.setType(2);
+        dto.setImages(List.of("http://dummy.jpg"));
+        dto.setTags(List.of("Java", "编程"));
+
+        String postId = postService.createPost(dto);
+
+        PostDoc savedPost = postRepository.findById(postId).orElseThrow();
+        List<String> dbTerms = savedPost.getSearchTerms();
+
+        System.out.println("数据库中的 searchTerms: " + dbTerms);
+
+        Assertions.assertNotNull(dbTerms);
+        // 【关键修复 2】: 接受 '多线程' 这个词 (Jieba 可能不拆分它)
+        boolean hasThread = dbTerms.contains("线程") || dbTerms.contains("多线程");
+        Assertions.assertTrue(hasThread, "应该包含 '线程' 或 '多线程'");
+    }
+
+    @Test
+    @DisplayName("测试全文搜索召回能力")
+    public void testFullSearch() throws InterruptedException { // 允许抛出中断异常
+        // A: 包含 "深圳"
+        createPost("深圳周末去哪儿", "可以在南山逛街", List.of("旅游"));
+
+        // B: 包含 "ArchLinux"
+        createPost("我的 ArchLinux 安装笔记", "sudo pacman -Syu", List.of("Linux", "OS"));
 
-        // E: 已删除的包含关键字的项 (不应被搜到)
-        PostDoc deletedPost = new PostDoc();
-        deletedPost.setTitle("ArchLinux 已删除");
-        deletedPost.setStatus(1);
-        deletedPost.setIsDeleted(1); // deleted
-        postRepository.save(deletedPost);
+        // C: 干扰项
+        createPost("广州早茶推荐", "凤爪排骨", List.of("美食"));
 
-        // --- 2. 执行搜索 ---
-        System.out.println(">>> 开始搜索关键词: " + keyword);
-        Map<String, Object> result = postService.searchPosts(keyword, 1, 10);
+        // 【关键】给 MongoDB 一点时间建索引 (500ms - 1s)
+        // 在真实生产环境不需要，但测试环境瞬间写入瞬间查容易出问题
+//        Thread.sleep(1000);
 
-        // --- 3. 验证结果 ---
-        List<?> records = (List<?>) result.get("records");
-        long total = (long) result.get("total");
+        // 1. 中文搜索
+        System.out.println(">>> 搜索: '深圳逛街'");
+        Map<String, Object> resultA = postService.searchPosts("深圳逛街", 1, 10);
+        List<?> listA = (List<?>) resultA.get("records");
 
-        System.out.println("搜索结果数量: " + total);
+        // 打印一下到底搜到了啥，方便调试
+        System.out.println("搜索结果 A: " + listA);
 
-        // 预期：应该找到 A, B, C 三条数据
-        Assertions.assertEquals(3, total, "应该找到3条匹配的帖子");
+        Assertions.assertEquals(1, listA.size(), "应该找到 1 条关于深圳的帖子");
 
-        // 验证排序（可选）：因为 tags 权重高，理论上 C 应该在前面，但 mongo score 计算复杂，这里只验证存在性
-        // 验证 D 和 E 不在结果中
+        // 2. 英文搜索
+        System.out.println(">>> 搜索: 'pacman'");
+        Map<String, Object> resultB = postService.searchPosts("pacman", 1, 10);
+        List<?> listB = (List<?>) resultB.get("records");
+        Assertions.assertEquals(1, listB.size(), "应该找到 ArchLinux 的帖子");
     }
 
-    private void createPost(String id, String title, String content, List<String> tags) {
-        PostDoc post = new PostDoc();
-        // post.setId(id); // 让 Mongo 自动生成 ID 也可以
-        post.setTitle(title);
-        post.setContent(content);
-        post.setTags(tags);
-        post.setUserId(1001L);
-        post.setUserNickname("Tester");
-        post.setUserAvatar("avatar.jpg");
-        post.setStatus(1); // 已发布
-        post.setIsDeleted(0); // 未删除
+    private void createPost(String title, String content, List<String> tags) {
+        PostCreateDTO dto = new PostCreateDTO();
+        dto.setTitle(title);
+        dto.setContent(content);
+        dto.setType(2);
+        dto.setImages(List.of("http://dummy.jpg"));
+        dto.setTags(tags);
+
+        // 1. 调用 Service 创建 (此时状态是 0)
+        String postId = postService.createPost(dto);
+
+        // 2. 【关键修复】手动把状态改为 1 (已发布)，否则搜不到！
+        PostDoc post = postRepository.findById(postId).orElseThrow();
+        post.setStatus(1);
         postRepository.save(post);
     }
 
-    @Test
-    @DisplayName("测试搜索候选词：中文匹配、标签优先、去重、状态过滤")
-    public void testGetSearchSuggestions() {
-        System.out.println("========== 开始测试搜索联想词 ==========");
-
-        // --- 1. 准备测试数据 ---
-
-        // 场景 A: 正常数据，标签包含 "深圳"
-        PostDoc post1 = new PostDoc();
-        post1.setTitle("周末去哪儿玩");
-        post1.setTags(List.of("深圳", "旅游")); // 命中标签
-        post1.setStatus(1);
-        post1.setIsDeleted(0);
-        postRepository.save(post1);
-
-        // 场景 B: 正常数据，标题包含 "深圳"
-        PostDoc post2 = new PostDoc();
-        post2.setTitle("深圳大学美食攻略"); // 命中标题
-        post2.setTags(List.of("美食", "探店"));
-        post2.setStatus(1);
-        post2.setIsDeleted(0);
-        postRepository.save(post2);
-
-        // 场景 C: 干扰数据（不包含关键词）
-        PostDoc post3 = new PostDoc();
-        post3.setTitle("广州塔一日游");
-        post3.setTags(List.of("广州"));
-        post3.setStatus(1);
-        post3.setIsDeleted(0);
-        postRepository.save(post3);
-
-        // 场景 D: 状态异常数据（包含关键词，但 不应该 被搜到）
-        PostDoc postDraft = new PostDoc();
-        postDraft.setTitle("深圳草稿箱");
-        postDraft.setTags(List.of("深圳"));
-        postDraft.setStatus(0); // 0: 审核中/草稿
-        postDraft.setIsDeleted(0);
-        postRepository.save(postDraft);
-
-        PostDoc postDeleted = new PostDoc();
-        postDeleted.setTitle("深圳已删除");
-        postDeleted.setTags(List.of("深圳"));
-        postDeleted.setStatus(1);
-        postDeleted.setIsDeleted(1); // 1: 已删除
-        postRepository.save(postDeleted);
-
-        // --- 2. 执行搜索 ---
-        String keyword = "深圳";
-        List<String> result = postService.getSearchSuggestions(keyword);
-
-        System.out.println("搜索关键词: " + keyword);
-        System.out.println("联想词结果: " + result);
-
-        // --- 3. 验证断言 ---
-
-        // 3.1 验证数量
-        // 预期结果应该是 ["深圳", "深圳大学美食攻略"] (顺序可能根据 Mongo 返回顺序略有不同，但逻辑上标签在前)
-        // 实际上 post1 的标题 "周末去哪儿玩" 不含关键词，不会进入结果
-        // post2 的标签 "美食", "探店" 不含关键词，不会进入结果
-        Assertions.assertTrue(result.size() >= 2, "应该至少找到2个相关建议");
-
-        // 3.2 验证内容匹配
-        Assertions.assertTrue(result.contains("深圳"), "结果应包含匹配的标签 '深圳'");
-        Assertions.assertTrue(result.contains("深圳大学美食攻略"), "结果应包含匹配的标题 '深圳大学美食攻略'");
-
-        // 3.3 验证过滤逻辑 (草稿和已删除的不应出现)
-        Assertions.assertFalse(result.contains("深圳草稿箱"), "不应包含草稿状态的帖子");
-        Assertions.assertFalse(result.contains("深圳已删除"), "不应包含已删除的帖子");
-
-        // 3.4 验证去重逻辑 (如果你有多个帖子都有 "深圳" 这个标签，结果里应该只有一个 "深圳")
-        long countTag = result.stream().filter(s -> s.equals("深圳")).count();
-        Assertions.assertEquals(1, countTag, "相同的建议词应该被去重");
-
-        // 3.5 验证优先级 (可选)
-        // 在我们的 Service 实现中，是先遍历 Tags 加入 Set，再遍历 Title 加入 Set。
-        // LinkedHashSet 会保留插入顺序。通常 post1 (匹配Tag) 会被先处理或 Tag 逻辑在前。
-        // 如果数据量小，Mongo 返回顺序通常是插入顺序。
-        // 只要断言包含即可，顺序对单元测试来说不是绝对强一致性要求。
-
-        System.out.println("✅ 搜索联想词测试通过");
-    }
 }
\ No newline at end of file
